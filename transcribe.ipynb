{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/papercore-dev/perfectly-jogyo/blob/main/transcribe.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QK-TJCTNcDVU"
      },
      "source": [
        "##Auto Transcribe Colab\n",
        "##Made by Cris140\n",
        "##If you want to use your own dataset,upload your wavs in the wavs folder and run the first and fourth cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Qfb5VEodT9fz"
      },
      "outputs": [],
      "source": [
        "#@title Click here to install everything\n",
        "%%capture\n",
        "!git clone https://github.com/Cris140/Tacotron2AutoTrim\n",
        "import os\n",
        "import imageio\n",
        "imageio.plugins.ffmpeg.download()\n",
        "os.makedirs(os.path.dirname('input/'), exist_ok=True)\n",
        "os.makedirs(os.path.dirname('wavs/'), exist_ok=True)\n",
        "os.makedirs(os.path.dirname('dataset/'), exist_ok=True)\n",
        "\n",
        "%cd Tacotron2AutoTrim\n",
        "!pip install -r requirements.txt\n",
        "!pip install yt-dlp\n",
        "!apt install ffmpeg\n",
        "!pip install ffmpeg-python\n",
        "!pip install transcribe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ESPUa9y3T_iC"
      },
      "outputs": [],
      "source": [
        "#@title Use this cell if you want to upload your own audio\n",
        "#@markdown Can be a long/short mp3 file of only one speaker.\n",
        "from google.colab import files\n",
        "import os\n",
        "%cd /content/input\n",
        "files.upload()\n",
        "for count, filename in enumerate(os.listdir(\"/content/input\")):\n",
        "  dst = \"audio\" + \".mp3\"\n",
        "  os.rename(\"/content/input/\"+ filename, \"/content/input/\" + dst)\n",
        "%cd /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "NBOGqOosilk_"
      },
      "outputs": [],
      "source": [
        "#@title Or if you prefer you can use an youtube video\n",
        "%%capture\n",
        "import os\n",
        "import sys\n",
        "os.makedirs(os.path.dirname('/wavs/'), exist_ok=True)\n",
        "%cd /content/input\n",
        "video_link = \"\" #@param {type:\"string\"}\n",
        "!yt-dlp -x --audio-format mp3 -o \"audio.mp3\" $video_link\n",
        "%cd /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "BnIbZPOFVeW5"
      },
      "outputs": [],
      "source": [
        "#@title Now use this cell to transcribe the file\n",
        "from google.colab import files\n",
        "import shutil\n",
        "import os\n",
        "import sys\n",
        "erase_audios_that_google_couldnt_transcribe = False #@param{type:\"boolean\"}\n",
        "file_exists1 = os.path.exists('/content/dataset/wavs')\n",
        "if file_exists1==True:\n",
        "    dir1= \"/content/dataset/wavs/\"\n",
        "    txt_file = \"/content/dataset/list.txt\"\n",
        "    # checking whether file exists or not\n",
        "    if os.path.exists(txt_file):\n",
        "        # removing the file using the os.remove() method\n",
        "        os.remove(txt_file)\n",
        "    else:\n",
        "        # file not found message\n",
        "        print(\"File not found in the directory\")\n",
        "    mp3_file = \"/content/input/audio.mp3\"\n",
        "    # checking whether file exists or not\n",
        "    if os.path.exists(mp3_file):\n",
        "        # removing the file using the os.remove() method\n",
        "        os.remove(mp3_file)\n",
        "    try:\n",
        "        shutil.rmtree(dir1)\n",
        "    except OSError as e:\n",
        "        print(\"Error: %s - %s.\" % (e.filename, e.strerror))\n",
        "    dir2= \"/content/wavs1/\"\n",
        "    try:\n",
        "        shutil.rmtree(dir2)\n",
        "    except OSError as e:\n",
        "        print(\"Error: %s - %s.\" % (e.filename, e.strerror))\n",
        "    # removing the file using the os.remove() method\n",
        "    os.remove(file_path)\n",
        "skip_large_duration_files =\"No\" #@param [\"Yes\", \"No\"]\n",
        "max_duration_of_audio =\"20\"#@param {type: \"string\"}\n",
        "minimum_silence_length =\"200\" #@param {type: \"string\"}\n",
        "silence_threshold =\"-40\" #@param {type: \"string\"}\n",
        "Language =\"Brazilian Portuguese\"#@param [\"English\", \"Spanish\", \"French\", \"German\", \"Italian\", \"Japanese\", \"Russian\", \"Brazilian Portuguese\", \"Polish\", \"Arabic\", \"Turkish\", \"Zulu\", \"Slovak\", \"Mandarin Chinese\", \"Czech\", \"Korean\"]\n",
        "max_duration_of_audio = int(max_duration_of_audio)\n",
        "silence_threshold = int(silence_threshold)\n",
        "minimum_silence_length = int(minimum_silence_length)\n",
        "lang = ''\n",
        "  \n",
        "lang_input = Language\n",
        "if Language == 'English':\n",
        "    Language = 'en-US'\n",
        "elif Language == 'Spanish':\n",
        "    Language = 'es-ES'\n",
        "elif Language == 'French':\n",
        "    Language = 'fr-FR'\n",
        "elif Language == 'German':\n",
        "    Language = 'de-DE'\n",
        "elif Language == 'Italian':\n",
        "    Language = 'it-IT'\n",
        "elif Language == 'Japanese':\n",
        "    Language = 'ja'\n",
        "    _encoding = 'utf-16'\n",
        "elif Language == 'Russian':\n",
        "    Language = 'ru'\n",
        "elif Language =='Arabic':\n",
        "    Language = 'ar-EG'\n",
        "elif Language == 'Brazilian Portuguese':\n",
        "    Language = 'pt-BR'\n",
        "elif Language == 'Polish':\n",
        "    Language = 'pl-PL'\n",
        "elif Language == 'Turkish':\n",
        "    Language = 'tr'\n",
        "elif Language == 'Zulu':\n",
        "    Language = 'zu'\n",
        "elif Language == 'Slovak':\n",
        "    Language = 'sk'\n",
        "elif Language == 'Mandarin Chinese':\n",
        "    Language = 'zh-CN'\n",
        "elif Language == 'Czech':\n",
        "    Language = 'cs'\n",
        "elif Language == 'Korean':\n",
        "    Language = 'ko-KR'\n",
        "else:\n",
        "    print('Invalid Language!')\n",
        "import re\n",
        "import shutil\n",
        "import sys\n",
        "from pydub import AudioSegment\n",
        "from pydub.silence import split_on_silence\n",
        "import speech_recognition as sr\n",
        "import glob\n",
        "import os\n",
        "\n",
        "import wave\n",
        "import contextlib\n",
        "\n",
        "import transcribe\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    \n",
        "    import imageio\n",
        "    imageio.plugins.ffmpeg.download()\n",
        "\n",
        "    file_number = 1\n",
        "\n",
        "    input_file = \"audio.mp3\"\n",
        "\n",
        "\n",
        "    _encoding = 'utf-8'\n",
        "file_exists = os.path.exists('/content/input/audio.mp3')\n",
        "if file_exists==True:\n",
        "    min_silence_len_var = minimum_silence_length\n",
        "    silence_thresh_var = silence_threshold\n",
        "\n",
        "    skip_large_duration_files_input = skip_large_duration_files\n",
        "    if skip_large_duration_files_input.strip().lower() == 'yes':\n",
        "        skip_large_duration_files = True\n",
        "    elif skip_large_duration_files_input.strip().lower() == 'no':\n",
        "        skip_large_duration_files = False\n",
        "    else:\n",
        "        skip_large_duration_files = True\n",
        "    \n",
        "    if skip_large_duration_files:\n",
        "        max_dur_audio = max_duration_of_audio\n",
        "    else:\n",
        "        max_dur_audio = 12\n",
        "    # assign files\n",
        "    input_file = '/content/input/' + input_file\n",
        "\n",
        "    # create dir if doesn't exist\n",
        "    os.makedirs(os.path.dirname('/content/wavs/'), exist_ok=True)\n",
        "\n",
        "    sound_file = AudioSegment.from_file(input_file)\n",
        "    sound_file = sound_file.set_frame_rate(22050)  # don't change this\n",
        "    sound_file = sound_file.set_channels(1)  # don't change this\n",
        "    audio_chunks = split_on_silence(sound_file, min_silence_len=min_silence_len_var,  # 1000 cuts at 1 second of silence. 500 is 0.5 sec\n",
        "                                    silence_thresh=silence_thresh_var)\n",
        "\n",
        "    for i, chunk in enumerate(audio_chunks):\n",
        "\n",
        "        if not len(os.listdir('/content/wavs')) == 0:\n",
        "            list_of_files = glob.glob('/content/wavs/*')  # * means all\n",
        "            latest_file = max(list_of_files, key=os.path.getctime)\n",
        "\n",
        "            # Extract numbers and cast them to int\n",
        "            list_of_nums = re.findall('\\\\d+', latest_file)\n",
        "\n",
        "            if int(list_of_nums[0]) >= file_number:\n",
        "                file_number = int(list_of_nums[0]) + 1\n",
        "\n",
        "        out_file = \"/content/wavs/{0}.wav\".format(file_number)\n",
        "        print(\"exporting\", out_file + '\\n')\n",
        "\n",
        "        chunk.export(out_file, format=\"wav\")\n",
        "\n",
        "        fname = out_file\n",
        "        with contextlib.closing(wave.open(fname, 'r')) as f:\n",
        "            frames = f.getnframes()\n",
        "            rate = f.getframerate()\n",
        "            duration = frames / float(rate)\n",
        "            #print('Duration:', duration)\n",
        "\n",
        "path, dirs, files1 = next(os.walk(\"/content/wavs/\"))\n",
        "file_count = len(files1)\n",
        "if os.path.isdir('/content/wavs1')==False:\n",
        "    shutil.copytree('/content/wavs', '/content/wavs1')\n",
        "for file in os.listdir(\"/content/wavs1/\"):\n",
        "\n",
        "  input_wav_file   = '/content/wavs1/'+file\n",
        "  output_wav_file  = input_wav_file\n",
        "  target_wav_time  = 3 * 1000 # 5 seconds (or 5000 milliseconds)\n",
        "\n",
        "  original_segment = AudioSegment.from_wav(input_wav_file)\n",
        "  silence_duration = target_wav_time - len(original_segment)\n",
        "  silenced_segment = AudioSegment.silent(duration=silence_duration)\n",
        "  combined_segment = silenced_segment + original_segment + silenced_segment\n",
        "  combined_segment.export(output_wav_file, format=\"wav\") \n",
        "\n",
        "# obtain path to \"english.wav\" in the same folder as this script\n",
        "from os import path\n",
        "__file__ = 'trans.py'\n",
        "# use the audio file as the audio source\n",
        "file_exists = os.path.exists('/content/input/audio.mp3')\n",
        "if file_exists==True:\n",
        "      pasta1=\"/content/wavs1/\"\n",
        "else:\n",
        "      pasta1=\"/content/wavs/\"\n",
        "os.chdir(pasta1)\n",
        "for file in os.listdir(\"/content/wavs1/\"):\n",
        "      pastaaudio = \"/content/wavs1/\"\n",
        "      AUDIO_FILE = pastaaudio + file\n",
        "      r = sr.Recognizer()\n",
        "      with sr.AudioFile(AUDIO_FILE) as source:\n",
        "          audio = r.record(source)  # read the entire audio file    \n",
        "      try:\n",
        "          # for testing purposes, we're just using the default API key\n",
        "          # to use another API key, use `r.recognize_google(audio, key=\"GOOGLE_SPEECH_RECOGNITION_API_KEY\", show_all=True)`\n",
        "          # instead of `r.recognize_google(audio, show_all=True)`\n",
        "          print(\"wavs/\"+file+\"|\"+ r.recognize_google(audio, language=Language), file=open(\"/content/dataset/list1.txt\", \"a\"))\n",
        "      except sr.UnknownValueError:\n",
        "           if erase_audios_that_google_couldnt_transcribe:\n",
        "                os.remove(\"/content/wavs/\"+file)\n",
        "           else:\n",
        "                print(\"Google wasn't able to transcribe the audio \"+file+\", Skipping it...\")\n",
        "      except sr.RequestError as e:\n",
        "          print(\"Could not request results from Googleeech Recognition service; {0}\".format(e))\n",
        "%cd /content/\n",
        "with open('/content/dataset/list1.txt', 'r') as istr:\n",
        "    with open('/content/dataset/list2.txt', 'w') as ostr:\n",
        "        for line in istr:\n",
        "            line = line.rstrip('\\n') + '.'\n",
        "            print(line, file=ostr)\n",
        "\n",
        "#@markdown ###Let this option turned off if you want to use wav2vec2 to transcribe\n",
        "download_dataset_when_finished = True #@param{type:\"boolean\"}\n",
        "!rm /content/dataset/list1.txt\n",
        "!mv /content/dataset/list2.txt /content/dataset/list.txt\n",
        "shutil.move(\"/content/wavs\",\"/content/dataset\")\n",
        "pasta=\"/content/wavs1\"\n",
        "try:\n",
        "    shutil.rmtree(pasta)\n",
        "except OSError as e:\n",
        "    print(\"Error: %s - %s.\" % (e.filename, e.strerror))\n",
        "if download_dataset_when_finished==True:\n",
        "      !zip -r /content/dataset.zip /content/dataset/      \n",
        "      files.download(\"/content/dataset.zip\")\n",
        "else:\n",
        "    !rm /content/input/audio.mp3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "uw1QP3ZUsvxv"
      },
      "outputs": [],
      "source": [
        "#@title Run this cell to install wav2vec2 dependencies\n",
        "#@markdown ###It will take some while to finished, when finished you can run the last cell\n",
        "%%capture\n",
        "!pip install -q soundfile git+git://github.com/pytorch/fairseq.git@b8ea8a9b72c82192da07e3377adf4ebbde16716d\n",
        "!pip install -q datasets\n",
        "!pip install -q transformers\n",
        "!pip install -q rpunct\n",
        "!sudo apt-get install swig\n",
        "!apt remove cmake\n",
        "!pip install -q cmake --upgrade\n",
        "!pip install -q jamspell\n",
        "!wget https://raw.githubusercontent.com/bakwc/JamSpell-models/master/en.tar.gz\n",
        "!tar -zxvf /content/en.tar.gz\n",
        "!pip install -q auditok\n",
        "if not os.path.exists('/content/Tacotron2AutoTrim/output'):\n",
        "    os.makedirs('/content/Tacotron2AutoTrim/output')\n",
        "if not os.path.exists('/content/Tacotron2AutoTrim/output/wavs'):\n",
        "    os.makedirs('/content/Tacotron2AutoTrim/output/wavs')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "xrJ1eMmTsmto"
      },
      "outputs": [],
      "source": [
        "#@title Transcribe using wav2vec\n",
        "Language =\"Brazilian Portuguese\"#@param [\"Brazilian Portuguese\", \"English\"]\n",
        "import soundfile as sf\n",
        "import torch\n",
        "from IPython.display import clear_output\n",
        "from datasets import load_dataset\n",
        "from transformers import Wav2Vec2Tokenizer, Wav2Vec2ForCTC\n",
        "import glob\n",
        "import os\n",
        "import librosa\n",
        "from rpunct import RestorePuncts\n",
        "import jamspell\n",
        "corrector = jamspell.TSpellCorrector()\n",
        "corrector.LoadLangModel('pt.bin')\n",
        "rpunct = RestorePuncts()\n",
        "Lang = Language\n",
        "if Language == \"English\":\n",
        "    Language = \"facebook/wav2vec2-large-960h-lv60-self\"\n",
        "if Language == \"Brazilian Portuguese\":\n",
        "    Language = \"jonatasgrosman/wav2vec2-large-xlsr-53-portuguese\"\n",
        "\n",
        "# comando para carregar o modelo\n",
        "tokenizer = Wav2Vec2Tokenizer.from_pretrained(Language)\n",
        "clear_output(wait=True)\n",
        "model = Wav2Vec2ForCTC.from_pretrained(Language)\n",
        "clear_output(wait=True)\n",
        "# converter o modelo para cuda, remova ou comente para usar a CPU\n",
        "model.cuda()\n",
        "\n",
        "print(\"Transcrevendo...\")\n",
        "transcript = open(\"/content/Tacotron2AutoTrim/output/list.txt\", \"a\")\n",
        "file = open(\"/content/Tacotron2AutoTrim/output/list.txt\",\"r+\")\n",
        "file. truncate(0)\n",
        "for file in sorted(glob.glob(os.path.join(\"/content/dataset/wavs\", '*.wav'))):\n",
        "  print(file)\n",
        "  # Ler arquivo wav a 16000hz\n",
        "\n",
        "  audio_input, sample_rate = librosa.load(file, sr=16000)\n",
        "\n",
        "  input_values = tokenizer(audio_input, sampling_rate = sample_rate, return_tensors=\"pt\", padding=\"longest\", batch_size = 25).input_values\n",
        "\n",
        "  input_values = input_values.cuda()\n",
        "\n",
        "  logits = model(input_values).logits\n",
        "  \n",
        "  predicted_ids = torch.argmax(logits, dim=-1)\n",
        "\n",
        "  # Começar transcrição\n",
        "\n",
        "  transcription = tokenizer.batch_decode(predicted_ids)\n",
        "\n",
        "  # Deixar em minúsculo.\n",
        "\n",
        "  output = transcription[0].lower()\n",
        "\n",
        "  # Para checar se não tem nada na transcrição\n",
        "\n",
        "  try:\n",
        "    # Pontuar!\n",
        "    output = rpunct.punctuate(corrector.FixFragment(output), lang='en')\n",
        "    transcript.write(f\"\\n{file}|{output}\")\n",
        "  except:\n",
        "    print(f\"{file} Couldn't punctuate for whatever reason. SKIPPING!\")\n",
        "\n",
        "  # Salvar arquivo\n",
        "  \n",
        "  print(output)\n",
        "\n",
        "transcript.close()\n",
        "\n",
        "filePath = r\"/content/dataset/list.txt\"\n",
        "file_str = \"\"\n",
        "\n",
        "with open(filePath,'r') as f:\n",
        "        next(f)\n",
        "        for line in f:\n",
        "            file_str = file_str + line\n",
        "\n",
        "with open(filePath, \"w\") as f:\n",
        "    f.write(file_str)\n",
        "\n",
        "# Write the file out again\n",
        "with open('/content/dataset/list.txt', 'r') as file:\n",
        "    sorted_data=sorted(file.readlines(), \n",
        "                       key=lambda item: int(item.rsplit('=',1)[-1].strip()))\n",
        "!!zip -r /content/dataset.zip /content/dataset\n",
        "download_dataset_when_finished = True #@param{type:\"boolean\"}\n",
        "if download_dataset_when_finished==True:\n",
        "    files.download(\"/content/dataset.zip\")\n",
        "    print(\"Transcrição Finalizada. :)\")\n",
        "else:\n",
        "    print(\"Transcrição Finalizada. :)\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Multilanguage Auto Transcriber.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}