{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "vc-run.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "33efzXGOWDx3",
        "79YIRAJiUdE9",
        "PaL5ju9sWPUO",
        "f1sw5nDwXWRJ",
        "vE3EDJyZXecO",
        "ZVTFLUVIacVG",
        "uSgpKI-ZcVbx"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/papercore-dev/perfectly-jogyo/blob/main/vc-run.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **⚠ GPU나 TPU를 이용한 비트코인 및 가상화폐 채굴은 금지되어 있습니다. ⚠**"
      ],
      "metadata": {
        "id": "ifxHY5Uq85fO"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXNKDE_BW-Kc"
      },
      "source": [
        "# 🐸TTS × YourTTS\n",
        "## VITS 기반 TTS 엔진 제작기\n",
        "\n",
        "제가 장담하건대, 저 포함 여러분들의 99% 이상은 TTS가 궁금하지, 그것을 운용시키는 무슨 Pytorch라던지, GAN, KSS, LJSpeech 같은 건 들어보지도 않았을 뿐더러 알기도 싫으실 겁니다.\n",
        "\n",
        "그래서 간단히 이 사이트 사용법에 대해서 설명을 하자면, TTS처럼 글자 입력해서 목소리가 나오는 건 절대 아닙니다. (gTTS를 쓰면 되긴 하지만, 귀찮아서 하진 않습니다.)\n",
        "\n",
        "따라서 여러분의 아무 말이나 하는 WAV 형식의 목소리 파일 (50건 이상 권장)과 말하고자 하는 문장이 포함된 WAV 형식의 목소리 파일 1건을 가져오셔서 진행하시면 되겠습니다.\n",
        "\n",
        "아래의 방법을 따라주세요!\n",
        "\n",
        "**✨ 추천 링크:**\n",
        "* 유튜브 영상에서 목소리를 추출해서 TTS를 제작하는 Colab [-> (Chris140님 감사합니다)](https://colab.research.google.com/github/papercore-dev/perfectly-jogyo/blob/main/transcribe.ipynb)\n",
        "* 여러가지 보이스들 [->](https://github.com/papercore-dev/perfectly-jogyo/tree/main/models)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33efzXGOWDx3"
      },
      "source": [
        "##🚀 **TTS 모델 설정하기**\n",
        "*숨겨진 셀 10개* 라고 적힌 부분 왼쪽의 큼지막한 재생 버튼을 눌러서 실행하시면 됩니다.\n",
        "\n",
        "보안 관련 경고가 나타나면은 **무시하고 계속**을 누르시면 됩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79YIRAJiUdE9"
      },
      "source": [
        "### 🐸TTS 설정하기\n",
        "Coqui라는 회사에서 제작한 TTS인데요, Coqui는 음성 인식 및 음성 합성을 주 업무로 하고 있는 회사에요.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2akFqoi7UiD4"
      },
      "source": [
        "!git clone https://github.com/Edresson/Coqui-TTS -b multilingual-torchaudio-SE TTS\n",
        "!pip install -q -e TTS/\n",
        "!pip install -q torchaudio==0.9.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PaL5ju9sWPUO"
      },
      "source": [
        "###✨ TTS 사전 설정값 다운로드\n",
        "사전 설정값, 즉 체크포인트 없이는 GPU 사용량이 높은 트레이닝 과정을 거쳐야 하는데, 이거 하시는 분들은 그런거 잘 모르실 거잖아요? 그래서 미리 해봤습니다 :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yICxxOSZWYJb"
      },
      "source": [
        "# 사전 설정값 (체크포인트)을 구글 드라이브에서 받습니다.\n",
        "\n",
        "# download config  \n",
        "!gdown --id 1-PfXD66l1ZpsZmJiC-vhL055CDSugLyP\n",
        "# download language json \n",
        "! gdown --id 1_Vb2_XHqcC0OcvRF82F883MTxfTRmerg\n",
        "# download speakers json\n",
        "! gdown --id 1SZ9GE0CBM-xGstiXH2-O2QWdmSXsBKdC -O speakers.json\n",
        "# download checkpoint\n",
        "! gdown --id 1sgEjHt0lbPSEw9-FSbC_mBoOPwNi87YR -O best_model.pth.tar"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1sw5nDwXWRJ"
      },
      "source": [
        "### ✨ 필요한 라이브러리 가져오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajwcjsizXYF9"
      },
      "source": [
        "import sys\n",
        "TTS_PATH = \"TTS/\"\n",
        "\n",
        "# add libraries into environment\n",
        "sys.path.append(TTS_PATH) # set this if TTS is not installed globally\n",
        "\n",
        "import os\n",
        "import string\n",
        "import time\n",
        "import argparse\n",
        "import json\n",
        "\n",
        "import numpy as np\n",
        "import IPython\n",
        "from IPython.display import Audio\n",
        "\n",
        "\n",
        "import torch\n",
        "\n",
        "from TTS.tts.utils.synthesis import synthesis\n",
        "from TTS.tts.utils.text.symbols import make_symbols, phonemes, symbols\n",
        "try:\n",
        "  from TTS.utils.audio import AudioProcessor\n",
        "except:\n",
        "  from TTS.utils.audio import AudioProcessor\n",
        "\n",
        "\n",
        "from TTS.tts.models import setup_model\n",
        "from TTS.config import load_config\n",
        "from TTS.tts.models.vits import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vE3EDJyZXecO"
      },
      "source": [
        "### 경로 설정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8NWL6h2XiBP"
      },
      "source": [
        "OUT_PATH = 'out/'\n",
        "\n",
        "# create output path\n",
        "os.makedirs(OUT_PATH, exist_ok=True)\n",
        "\n",
        "# model vars \n",
        "MODEL_PATH = 'best_model.pth.tar'\n",
        "CONFIG_PATH = 'config.json'\n",
        "TTS_LANGUAGES = \"language_ids.json\"\n",
        "TTS_SPEAKERS = \"speakers.json\"\n",
        "USE_CUDA = torch.cuda.is_available()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVTFLUVIacVG"
      },
      "source": [
        "### 모델 복원"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygPFBC-UafNK"
      },
      "source": [
        "# load the config\n",
        "C = load_config(CONFIG_PATH)\n",
        "\n",
        "\n",
        "# load the audio processor\n",
        "ap = AudioProcessor(**C.audio)\n",
        "\n",
        "speaker_embedding = None\n",
        "\n",
        "C.model_args['d_vector_file'] = TTS_SPEAKERS\n",
        "C.model_args['use_speaker_encoder_as_loss'] = False\n",
        "\n",
        "model = setup_model(C)\n",
        "model.language_manager.set_language_ids_from_file(TTS_LANGUAGES)\n",
        "# print(model.language_manager.num_languages, model.embedded_language_dim)\n",
        "# print(model.emb_l)\n",
        "cp = torch.load(MODEL_PATH, map_location=torch.device('cpu'))\n",
        "# remove speaker encoder\n",
        "model_weights = cp['model'].copy()\n",
        "for key in list(model_weights.keys()):\n",
        "  if \"speaker_encoder\" in key:\n",
        "    del model_weights[key]\n",
        "\n",
        "model.load_state_dict(model_weights)\n",
        "\n",
        "\n",
        "model.eval()\n",
        "\n",
        "if USE_CUDA:\n",
        "    model = model.cuda()\n",
        "\n",
        "# synthesize voice\n",
        "use_griffin_lim = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSgpKI-ZcVbx"
      },
      "source": [
        "##🚀 **음성 인코더 설정**\n",
        "음성 합성은 다 끝났는데, 결과물이 없다면 반쪽짜리 TTS가 되는지라, 인코더도 설정하려 해요.\n",
        "\n",
        "아까처럼 ▶️ 버튼을 눌러주세요!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3TaCzONgyND"
      },
      "source": [
        "### ✨ 라이브러리 설치\n",
        "음성의 질을 균등하게 해주는 FFMPEG Normalize와, 여러 음성을 합치는 Pydub을 설치해요."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfnuqL4Zd4Zz"
      },
      "source": [
        "! pip install -q pydub ffmpeg-normalize"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJkRPcD9g2nl"
      },
      "source": [
        "### ✨ 경로 설정\n",
        "체크포인트 몇개만 더 받을게요!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fRFfyZFeKuR"
      },
      "source": [
        "CONFIG_SE_PATH = \"config_se.json\"\n",
        "CHECKPOINT_SE_PATH = \"SE_checkpoint.pth.tar\"\n",
        "\n",
        "# download config \n",
        "! gdown --id  19cDrhZZ0PfKf2Zhr_ebB-QASRw844Tn1 -O $CONFIG_SE_PATH\n",
        "# download checkpoint  \n",
        "! gdown --id   17JsW6h6TIh7-LkU2EvB_gnNrPcdBxt7X -O $CHECKPOINT_SE_PATH"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYZ9YC_LhAjY"
      },
      "source": [
        "###Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnWyPs7Vfxa2"
      },
      "source": [
        "from TTS.tts.utils.speakers import SpeakerManager\n",
        "from pydub import AudioSegment\n",
        "from google.colab import files\n",
        "import librosa"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHUPL0TahHjZ"
      },
      "source": [
        "###Load the Speaker encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnkL2GNXhLUs"
      },
      "source": [
        "SE_speaker_manager = SpeakerManager(encoder_model_path=CHECKPOINT_SE_PATH, encoder_config_path=CONFIG_SE_PATH, use_cuda=USE_CUDA)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yc-OM81nhDDe"
      },
      "source": [
        "###Define helper function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRvXOFPKgVLi"
      },
      "source": [
        "def compute_spec(ref_file):\n",
        "  y, sr = librosa.load(ref_file, sr=ap.sample_rate)\n",
        "  spec = ap.spectrogram(y)\n",
        "  spec = torch.FloatTensor(spec).unsqueeze(0)\n",
        "  return spec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mf4nuuFHfLBN"
      },
      "source": [
        "##🚀 **음성 합성하기**\n",
        "자~ 이제 설정이 끝났습니다!\n",
        "이제부터 음성 합성을 하고자 하는데요,\n",
        "\n",
        "이름과 달리 그리 어렵지 않습니다.\n",
        "한번 직접 해봐요!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zy86QKuFtWEo"
      },
      "source": [
        "###✨음성 업로드"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6L7hpMkvYXrd"
      },
      "source": [
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-7FwNJafNul",
        "cellView": "form"
      },
      "source": [
        "#@title 🎤 **새 보이스 제작하기**<br>원하는 보이스가 없다면, 새로운 보이스를 제작해도 좋아요.<br>**보이스 파일의 형식은 WAV (파형 오디오) 형식의 파일 필수, 50건 이상의 파일 권장 (좋은 결과를 얻을 수 있어요)입니다.**\n",
        "\n",
        "print(\"변조하고자 하는 이의 원본 목소리를 업로드합니다.:\")\n",
        "target_files = files.upload()\n",
        "target_files = list(target_files.keys())\n",
        "for sample in target_files:\n",
        "    !ffmpeg-normalize $sample -nt rms -t=-27 -o $sample -ar 16000 -f"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgftFAsd5gxE",
        "cellView": "form"
      },
      "source": [
        "#@title 🎤 **아무 말이나 올리기**<br>자신의 보이스를 올리세요.<br>**보이스 파일의 형식은 WAV (파형 오디오) 형식의 파일 필수, 50건 이상의 파일 권장 (좋은 결과를 얻을 수 있어요)입니다.**\n",
        "print(\"Select driving speaker reference audios files:\")\n",
        "driving_files = files.upload()\n",
        "driving_files = list(driving_files.keys())\n",
        "for sample in driving_files:\n",
        "    !ffmpeg-normalize $sample -nt rms -t=-27 -o $sample -ar 16000 -f"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jeQ9O6llm8D5",
        "cellView": "form"
      },
      "source": [
        "#@title 🎤 **대상이 할 말을 올리기**<br>**보이스 파일의 형식은 WAV (파형 오디오) 형식의 파일 필수, 1건의 파일 필수입니다.**\n",
        "\n",
        "print(\"변조하고 싶은 말을 올리세요.\")\n",
        "driving_file = files.upload()\n",
        "driving_file = list(driving_file.keys())\n",
        "for sample in driving_file:\n",
        "    !ffmpeg-normalize $sample -nt rms -t=-27 -o $sample -ar 16000 -f\n",
        "driving_file = driving_file[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvPu94pEqAEK"
      },
      "source": [
        "###✨ AI의 학습 단계"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_DFwguzXEqH",
        "cellView": "form"
      },
      "source": [
        "#@title 🎤 **새 보이스 학습하기**<br>보이스 학습이 완료되었다면, 이 값을 복사해서, <a href=\"https://github.com/papercore-dev/perfectly-jogyo/issues/new\">깃허브 이슈를 제작</a>하여 누구나 사용할 수 있게 도와주시면 감사하겠습니다.\n",
        "\n",
        "target_emb = SE_speaker_manager.compute_d_vector_from_clip(target_files)\n",
        "target_emb = torch.FloatTensor(target_emb).unsqueeze(0)\n",
        "print('보이스 값입니다. 다음 줄부터 복사해주세요! \\n')\n",
        "print(target_emb)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzdZmeQ_qIP8",
        "cellView": "form"
      },
      "source": [
        "#@title 🎤 **내 보이스 학습하고 합성하기**\n",
        "\n",
        "target_emb = input (\"보이스 txt파일의 값을 입력하세요 :\")\n",
        "\n",
        "if driving_emb is None:\n",
        "    driving_emb = SE_speaker_manager.compute_d_vector_from_clip(driving_files)\n",
        "    driving_emb = torch.FloatTensor(driving_emb).unsqueeze(0)\n",
        "\n",
        "driving_spec = compute_spec(driving_file)\n",
        "y_lengths = torch.tensor([driving_spec.size(-1)])\n",
        "if USE_CUDA:\n",
        "    ref_wav_voc, _, _ = model.voice_conversion(driving_spec.cuda(), y_lengths.cuda(), driving_emb.cuda(), target_emb.cuda())\n",
        "    ref_wav_voc = ref_wav_voc.squeeze().cpu().detach().numpy()\n",
        "else:\n",
        "    ref_wav_voc, _, _ = model.voice_conversion(driving_spec, y_lengths, driving_emb, target_emb)\n",
        "    ref_wav_voc = ref_wav_voc.squeeze().detach().numpy()\n",
        "\n",
        "\n",
        "print(\"결과물입니다:\")\n",
        "IPython.display.display(Audio(ref_wav_voc, rate=ap.sample_rate))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}