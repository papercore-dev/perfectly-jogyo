{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "vc-run.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "33efzXGOWDx3",
        "79YIRAJiUdE9",
        "PaL5ju9sWPUO",
        "f1sw5nDwXWRJ",
        "vE3EDJyZXecO",
        "ZVTFLUVIacVG",
        "uSgpKI-ZcVbx"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/papercore-dev/perfectly-jogyo/blob/main/vc-run.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **âš  GPUë‚˜ TPUë¥¼ ì´ìš©í•œ ë¹„íŠ¸ì½”ì¸ ë° ê°€ìƒí™”í ì±„êµ´ì€ ê¸ˆì§€ë˜ì–´ ìˆìŠµë‹ˆë‹¤. âš **"
      ],
      "metadata": {
        "id": "ifxHY5Uq85fO"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXNKDE_BW-Kc"
      },
      "source": [
        "# ğŸ¸TTS Ã— YourTTS\n",
        "## VITS ê¸°ë°˜ TTS ì—”ì§„ ì œì‘ê¸°\n",
        "\n",
        "ì œê°€ ì¥ë‹´í•˜ê±´ëŒ€, ì € í¬í•¨ ì—¬ëŸ¬ë¶„ë“¤ì˜ 99% ì´ìƒì€ TTSê°€ ê¶ê¸ˆí•˜ì§€, ê·¸ê²ƒì„ ìš´ìš©ì‹œí‚¤ëŠ” ë¬´ìŠ¨ Pytorchë¼ë˜ì§€, GAN, KSS, LJSpeech ê°™ì€ ê±´ ë“¤ì–´ë³´ì§€ë„ ì•Šì•˜ì„ ë¿ë”ëŸ¬ ì•Œê¸°ë„ ì‹«ìœ¼ì‹¤ ê²ë‹ˆë‹¤.\n",
        "\n",
        "ê·¸ë˜ì„œ ê°„ë‹¨íˆ ì´ ì‚¬ì´íŠ¸ ì‚¬ìš©ë²•ì— ëŒ€í•´ì„œ ì„¤ëª…ì„ í•˜ìë©´, TTSì²˜ëŸ¼ ê¸€ì ì…ë ¥í•´ì„œ ëª©ì†Œë¦¬ê°€ ë‚˜ì˜¤ëŠ” ê±´ ì ˆëŒ€ ì•„ë‹™ë‹ˆë‹¤. (gTTSë¥¼ ì“°ë©´ ë˜ê¸´ í•˜ì§€ë§Œ, ê·€ì°®ì•„ì„œ í•˜ì§„ ì•ŠìŠµë‹ˆë‹¤.)\n",
        "\n",
        "ë”°ë¼ì„œ ì—¬ëŸ¬ë¶„ì˜ ì•„ë¬´ ë§ì´ë‚˜ í•˜ëŠ” WAV í˜•ì‹ì˜ ëª©ì†Œë¦¬ íŒŒì¼ (50ê±´ ì´ìƒ ê¶Œì¥)ê³¼ ë§í•˜ê³ ì í•˜ëŠ” ë¬¸ì¥ì´ í¬í•¨ëœ WAV í˜•ì‹ì˜ ëª©ì†Œë¦¬ íŒŒì¼ 1ê±´ì„ ê°€ì ¸ì˜¤ì…”ì„œ ì§„í–‰í•˜ì‹œë©´ ë˜ê² ìŠµë‹ˆë‹¤.\n",
        "\n",
        "ì•„ë˜ì˜ ë°©ë²•ì„ ë”°ë¼ì£¼ì„¸ìš”!\n",
        "\n",
        "**âœ¨ ì¶”ì²œ ë§í¬:**\n",
        "* ìœ íŠœë¸Œ ì˜ìƒì—ì„œ ëª©ì†Œë¦¬ë¥¼ ì¶”ì¶œí•´ì„œ TTSë¥¼ ì œì‘í•˜ëŠ” Colab [-> (Chris140ë‹˜ ê°ì‚¬í•©ë‹ˆë‹¤)](https://colab.research.google.com/github/papercore-dev/perfectly-jogyo/blob/main/transcribe.ipynb)\n",
        "* ì—¬ëŸ¬ê°€ì§€ ë³´ì´ìŠ¤ë“¤ [->](https://github.com/papercore-dev/perfectly-jogyo/tree/main/models)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33efzXGOWDx3"
      },
      "source": [
        "##ğŸš€ **TTS ëª¨ë¸ ì„¤ì •í•˜ê¸°**\n",
        "*ìˆ¨ê²¨ì§„ ì…€ 10ê°œ* ë¼ê³  ì íŒ ë¶€ë¶„ ì™¼ìª½ì˜ í¼ì§€ë§‰í•œ ì¬ìƒ ë²„íŠ¼ì„ ëˆŒëŸ¬ì„œ ì‹¤í–‰í•˜ì‹œë©´ ë©ë‹ˆë‹¤.\n",
        "\n",
        "ë³´ì•ˆ ê´€ë ¨ ê²½ê³ ê°€ ë‚˜íƒ€ë‚˜ë©´ì€ **ë¬´ì‹œí•˜ê³  ê³„ì†**ì„ ëˆ„ë¥´ì‹œë©´ ë©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79YIRAJiUdE9"
      },
      "source": [
        "### ğŸ¸TTS ì„¤ì •í•˜ê¸°\n",
        "Coquië¼ëŠ” íšŒì‚¬ì—ì„œ ì œì‘í•œ TTSì¸ë°ìš”, CoquiëŠ” ìŒì„± ì¸ì‹ ë° ìŒì„± í•©ì„±ì„ ì£¼ ì—…ë¬´ë¡œ í•˜ê³  ìˆëŠ” íšŒì‚¬ì—ìš”.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2akFqoi7UiD4"
      },
      "source": [
        "!git clone https://github.com/Edresson/Coqui-TTS -b multilingual-torchaudio-SE TTS\n",
        "!pip install -q -e TTS/\n",
        "!pip install -q torchaudio==0.9.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PaL5ju9sWPUO"
      },
      "source": [
        "###âœ¨ TTS ì‚¬ì „ ì„¤ì •ê°’ ë‹¤ìš´ë¡œë“œ\n",
        "ì‚¬ì „ ì„¤ì •ê°’, ì¦‰ ì²´í¬í¬ì¸íŠ¸ ì—†ì´ëŠ” GPU ì‚¬ìš©ëŸ‰ì´ ë†’ì€ íŠ¸ë ˆì´ë‹ ê³¼ì •ì„ ê±°ì³ì•¼ í•˜ëŠ”ë°, ì´ê±° í•˜ì‹œëŠ” ë¶„ë“¤ì€ ê·¸ëŸ°ê±° ì˜ ëª¨ë¥´ì‹¤ ê±°ì–ì•„ìš”? ê·¸ë˜ì„œ ë¯¸ë¦¬ í•´ë´¤ìŠµë‹ˆë‹¤ :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yICxxOSZWYJb"
      },
      "source": [
        "# ì‚¬ì „ ì„¤ì •ê°’ (ì²´í¬í¬ì¸íŠ¸)ì„ êµ¬ê¸€ ë“œë¼ì´ë¸Œì—ì„œ ë°›ìŠµë‹ˆë‹¤.\n",
        "\n",
        "# download config  \n",
        "!gdown --id 1-PfXD66l1ZpsZmJiC-vhL055CDSugLyP\n",
        "# download language json \n",
        "! gdown --id 1_Vb2_XHqcC0OcvRF82F883MTxfTRmerg\n",
        "# download speakers json\n",
        "! gdown --id 1SZ9GE0CBM-xGstiXH2-O2QWdmSXsBKdC -O speakers.json\n",
        "# download checkpoint\n",
        "! gdown --id 1sgEjHt0lbPSEw9-FSbC_mBoOPwNi87YR -O best_model.pth.tar"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1sw5nDwXWRJ"
      },
      "source": [
        "### âœ¨ í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ê°€ì ¸ì˜¤ê¸°"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajwcjsizXYF9"
      },
      "source": [
        "import sys\n",
        "TTS_PATH = \"TTS/\"\n",
        "\n",
        "# add libraries into environment\n",
        "sys.path.append(TTS_PATH) # set this if TTS is not installed globally\n",
        "\n",
        "import os\n",
        "import string\n",
        "import time\n",
        "import argparse\n",
        "import json\n",
        "\n",
        "import numpy as np\n",
        "import IPython\n",
        "from IPython.display import Audio\n",
        "\n",
        "\n",
        "import torch\n",
        "\n",
        "from TTS.tts.utils.synthesis import synthesis\n",
        "from TTS.tts.utils.text.symbols import make_symbols, phonemes, symbols\n",
        "try:\n",
        "  from TTS.utils.audio import AudioProcessor\n",
        "except:\n",
        "  from TTS.utils.audio import AudioProcessor\n",
        "\n",
        "\n",
        "from TTS.tts.models import setup_model\n",
        "from TTS.config import load_config\n",
        "from TTS.tts.models.vits import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vE3EDJyZXecO"
      },
      "source": [
        "### ê²½ë¡œ ì„¤ì •"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8NWL6h2XiBP"
      },
      "source": [
        "OUT_PATH = 'out/'\n",
        "\n",
        "# create output path\n",
        "os.makedirs(OUT_PATH, exist_ok=True)\n",
        "\n",
        "# model vars \n",
        "MODEL_PATH = 'best_model.pth.tar'\n",
        "CONFIG_PATH = 'config.json'\n",
        "TTS_LANGUAGES = \"language_ids.json\"\n",
        "TTS_SPEAKERS = \"speakers.json\"\n",
        "USE_CUDA = torch.cuda.is_available()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVTFLUVIacVG"
      },
      "source": [
        "### ëª¨ë¸ ë³µì›"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygPFBC-UafNK"
      },
      "source": [
        "# load the config\n",
        "C = load_config(CONFIG_PATH)\n",
        "\n",
        "\n",
        "# load the audio processor\n",
        "ap = AudioProcessor(**C.audio)\n",
        "\n",
        "speaker_embedding = None\n",
        "\n",
        "C.model_args['d_vector_file'] = TTS_SPEAKERS\n",
        "C.model_args['use_speaker_encoder_as_loss'] = False\n",
        "\n",
        "model = setup_model(C)\n",
        "model.language_manager.set_language_ids_from_file(TTS_LANGUAGES)\n",
        "# print(model.language_manager.num_languages, model.embedded_language_dim)\n",
        "# print(model.emb_l)\n",
        "cp = torch.load(MODEL_PATH, map_location=torch.device('cpu'))\n",
        "# remove speaker encoder\n",
        "model_weights = cp['model'].copy()\n",
        "for key in list(model_weights.keys()):\n",
        "  if \"speaker_encoder\" in key:\n",
        "    del model_weights[key]\n",
        "\n",
        "model.load_state_dict(model_weights)\n",
        "\n",
        "\n",
        "model.eval()\n",
        "\n",
        "if USE_CUDA:\n",
        "    model = model.cuda()\n",
        "\n",
        "# synthesize voice\n",
        "use_griffin_lim = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSgpKI-ZcVbx"
      },
      "source": [
        "##ğŸš€ **ìŒì„± ì¸ì½”ë” ì„¤ì •**\n",
        "ìŒì„± í•©ì„±ì€ ë‹¤ ëë‚¬ëŠ”ë°, ê²°ê³¼ë¬¼ì´ ì—†ë‹¤ë©´ ë°˜ìª½ì§œë¦¬ TTSê°€ ë˜ëŠ”ì§€ë¼, ì¸ì½”ë”ë„ ì„¤ì •í•˜ë ¤ í•´ìš”.\n",
        "\n",
        "ì•„ê¹Œì²˜ëŸ¼ â–¶ï¸ ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3TaCzONgyND"
      },
      "source": [
        "### âœ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n",
        "ìŒì„±ì˜ ì§ˆì„ ê· ë“±í•˜ê²Œ í•´ì£¼ëŠ” FFMPEG Normalizeì™€, ì—¬ëŸ¬ ìŒì„±ì„ í•©ì¹˜ëŠ” Pydubì„ ì„¤ì¹˜í•´ìš”."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfnuqL4Zd4Zz"
      },
      "source": [
        "! pip install -q pydub ffmpeg-normalize"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJkRPcD9g2nl"
      },
      "source": [
        "### âœ¨ ê²½ë¡œ ì„¤ì •\n",
        "ì²´í¬í¬ì¸íŠ¸ ëª‡ê°œë§Œ ë” ë°›ì„ê²Œìš”!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fRFfyZFeKuR"
      },
      "source": [
        "CONFIG_SE_PATH = \"config_se.json\"\n",
        "CHECKPOINT_SE_PATH = \"SE_checkpoint.pth.tar\"\n",
        "\n",
        "# download config \n",
        "! gdown --id  19cDrhZZ0PfKf2Zhr_ebB-QASRw844Tn1 -O $CONFIG_SE_PATH\n",
        "# download checkpoint  \n",
        "! gdown --id   17JsW6h6TIh7-LkU2EvB_gnNrPcdBxt7X -O $CHECKPOINT_SE_PATH"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYZ9YC_LhAjY"
      },
      "source": [
        "###Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnWyPs7Vfxa2"
      },
      "source": [
        "from TTS.tts.utils.speakers import SpeakerManager\n",
        "from pydub import AudioSegment\n",
        "from google.colab import files\n",
        "import librosa"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHUPL0TahHjZ"
      },
      "source": [
        "###Load the Speaker encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnkL2GNXhLUs"
      },
      "source": [
        "SE_speaker_manager = SpeakerManager(encoder_model_path=CHECKPOINT_SE_PATH, encoder_config_path=CONFIG_SE_PATH, use_cuda=USE_CUDA)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yc-OM81nhDDe"
      },
      "source": [
        "###Define helper function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRvXOFPKgVLi"
      },
      "source": [
        "def compute_spec(ref_file):\n",
        "  y, sr = librosa.load(ref_file, sr=ap.sample_rate)\n",
        "  spec = ap.spectrogram(y)\n",
        "  spec = torch.FloatTensor(spec).unsqueeze(0)\n",
        "  return spec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mf4nuuFHfLBN"
      },
      "source": [
        "##ğŸš€ **ìŒì„± í•©ì„±í•˜ê¸°**\n",
        "ì~ ì´ì œ ì„¤ì •ì´ ëë‚¬ìŠµë‹ˆë‹¤!\n",
        "ì´ì œë¶€í„° ìŒì„± í•©ì„±ì„ í•˜ê³ ì í•˜ëŠ”ë°ìš”,\n",
        "\n",
        "ì´ë¦„ê³¼ ë‹¬ë¦¬ ê·¸ë¦¬ ì–´ë µì§€ ì•ŠìŠµë‹ˆë‹¤.\n",
        "í•œë²ˆ ì§ì ‘ í•´ë´ìš”!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zy86QKuFtWEo"
      },
      "source": [
        "###âœ¨ìŒì„± ì—…ë¡œë“œ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6L7hpMkvYXrd"
      },
      "source": [
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-7FwNJafNul",
        "cellView": "form"
      },
      "source": [
        "#@title ğŸ¤ **ìƒˆ ë³´ì´ìŠ¤ ì œì‘í•˜ê¸°**<br>ì›í•˜ëŠ” ë³´ì´ìŠ¤ê°€ ì—†ë‹¤ë©´, ìƒˆë¡œìš´ ë³´ì´ìŠ¤ë¥¼ ì œì‘í•´ë„ ì¢‹ì•„ìš”.<br>**ë³´ì´ìŠ¤ íŒŒì¼ì˜ í˜•ì‹ì€ WAV (íŒŒí˜• ì˜¤ë””ì˜¤) í˜•ì‹ì˜ íŒŒì¼ í•„ìˆ˜, 50ê±´ ì´ìƒì˜ íŒŒì¼ ê¶Œì¥ (ì¢‹ì€ ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆì–´ìš”)ì…ë‹ˆë‹¤.**\n",
        "\n",
        "print(\"ë³€ì¡°í•˜ê³ ì í•˜ëŠ” ì´ì˜ ì›ë³¸ ëª©ì†Œë¦¬ë¥¼ ì—…ë¡œë“œí•©ë‹ˆë‹¤.:\")\n",
        "target_files = files.upload()\n",
        "target_files = list(target_files.keys())\n",
        "for sample in target_files:\n",
        "    !ffmpeg-normalize $sample -nt rms -t=-27 -o $sample -ar 16000 -f"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgftFAsd5gxE",
        "cellView": "form"
      },
      "source": [
        "#@title ğŸ¤ **ì•„ë¬´ ë§ì´ë‚˜ ì˜¬ë¦¬ê¸°**<br>ìì‹ ì˜ ë³´ì´ìŠ¤ë¥¼ ì˜¬ë¦¬ì„¸ìš”.<br>**ë³´ì´ìŠ¤ íŒŒì¼ì˜ í˜•ì‹ì€ WAV (íŒŒí˜• ì˜¤ë””ì˜¤) í˜•ì‹ì˜ íŒŒì¼ í•„ìˆ˜, 50ê±´ ì´ìƒì˜ íŒŒì¼ ê¶Œì¥ (ì¢‹ì€ ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆì–´ìš”)ì…ë‹ˆë‹¤.**\n",
        "print(\"Select driving speaker reference audios files:\")\n",
        "driving_files = files.upload()\n",
        "driving_files = list(driving_files.keys())\n",
        "for sample in driving_files:\n",
        "    !ffmpeg-normalize $sample -nt rms -t=-27 -o $sample -ar 16000 -f"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jeQ9O6llm8D5",
        "cellView": "form"
      },
      "source": [
        "#@title ğŸ¤ **ëŒ€ìƒì´ í•  ë§ì„ ì˜¬ë¦¬ê¸°**<br>**ë³´ì´ìŠ¤ íŒŒì¼ì˜ í˜•ì‹ì€ WAV (íŒŒí˜• ì˜¤ë””ì˜¤) í˜•ì‹ì˜ íŒŒì¼ í•„ìˆ˜, 1ê±´ì˜ íŒŒì¼ í•„ìˆ˜ì…ë‹ˆë‹¤.**\n",
        "\n",
        "print(\"ë³€ì¡°í•˜ê³  ì‹¶ì€ ë§ì„ ì˜¬ë¦¬ì„¸ìš”.\")\n",
        "driving_file = files.upload()\n",
        "driving_file = list(driving_file.keys())\n",
        "for sample in driving_file:\n",
        "    !ffmpeg-normalize $sample -nt rms -t=-27 -o $sample -ar 16000 -f\n",
        "driving_file = driving_file[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvPu94pEqAEK"
      },
      "source": [
        "###âœ¨ AIì˜ í•™ìŠµ ë‹¨ê³„"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_DFwguzXEqH",
        "cellView": "form"
      },
      "source": [
        "#@title ğŸ¤ **ìƒˆ ë³´ì´ìŠ¤ í•™ìŠµí•˜ê¸°**<br>ë³´ì´ìŠ¤ í•™ìŠµì´ ì™„ë£Œë˜ì—ˆë‹¤ë©´, ì´ ê°’ì„ ë³µì‚¬í•´ì„œ, <a href=\"https://github.com/papercore-dev/perfectly-jogyo/issues/new\">ê¹ƒí—ˆë¸Œ ì´ìŠˆë¥¼ ì œì‘</a>í•˜ì—¬ ëˆ„êµ¬ë‚˜ ì‚¬ìš©í•  ìˆ˜ ìˆê²Œ ë„ì™€ì£¼ì‹œë©´ ê°ì‚¬í•˜ê² ìŠµë‹ˆë‹¤.\n",
        "\n",
        "target_emb = SE_speaker_manager.compute_d_vector_from_clip(target_files)\n",
        "target_emb = torch.FloatTensor(target_emb).unsqueeze(0)\n",
        "print('ë³´ì´ìŠ¤ ê°’ì…ë‹ˆë‹¤. ë‹¤ìŒ ì¤„ë¶€í„° ë³µì‚¬í•´ì£¼ì„¸ìš”! \\n')\n",
        "print(target_emb)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzdZmeQ_qIP8",
        "cellView": "form"
      },
      "source": [
        "#@title ğŸ¤ **ë‚´ ë³´ì´ìŠ¤ í•™ìŠµí•˜ê³  í•©ì„±í•˜ê¸°**\n",
        "\n",
        "target_emb = input (\"ë³´ì´ìŠ¤ txtíŒŒì¼ì˜ ê°’ì„ ì…ë ¥í•˜ì„¸ìš” :\")\n",
        "\n",
        "if driving_emb is None:\n",
        "    driving_emb = SE_speaker_manager.compute_d_vector_from_clip(driving_files)\n",
        "    driving_emb = torch.FloatTensor(driving_emb).unsqueeze(0)\n",
        "\n",
        "driving_spec = compute_spec(driving_file)\n",
        "y_lengths = torch.tensor([driving_spec.size(-1)])\n",
        "if USE_CUDA:\n",
        "    ref_wav_voc, _, _ = model.voice_conversion(driving_spec.cuda(), y_lengths.cuda(), driving_emb.cuda(), target_emb.cuda())\n",
        "    ref_wav_voc = ref_wav_voc.squeeze().cpu().detach().numpy()\n",
        "else:\n",
        "    ref_wav_voc, _, _ = model.voice_conversion(driving_spec, y_lengths, driving_emb, target_emb)\n",
        "    ref_wav_voc = ref_wav_voc.squeeze().detach().numpy()\n",
        "\n",
        "\n",
        "print(\"ê²°ê³¼ë¬¼ì…ë‹ˆë‹¤:\")\n",
        "IPython.display.display(Audio(ref_wav_voc, rate=ap.sample_rate))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}